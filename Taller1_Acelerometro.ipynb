{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "027bfd18-62c4-46c9-9075-f2b53f00e9c9",
     "showTitle": false,
     "title": ""
    },
    "id": "Ynx1TXvk_S4g"
   },
   "source": [
    "### **Autores**\n",
    "\n",
    "JUAN DAVID GARCIA MEJIA ID UAO: 2233216\n",
    "\n",
    "JOHAN DAVID ROMERO RODRIGUEZ ID UAO:2235517\n",
    "\n",
    "EDWIN JAVIER CHAPARRO ARBOLEDA ID UAO: 2227299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "355f3586-142b-4ec5-ae76-5c703ac2473c",
     "showTitle": false,
     "title": ""
    },
    "id": "r4zNS-Eo_hPD"
   },
   "source": [
    "### **Introducción:**\n",
    "\n",
    "En este trabajo, se aborda el problema de la clasificación de movimientos a partir de datos de un acelerómetro. La capacidad de reconocer e identificar diferentes movimientos o actividades físicas tiene aplicaciones en campos como el monitoreo de la actividad física, la rehabilitación y el entrenamiento deportivo. El objetivo principal es desarrollar modelos de aprendizaje automático capaces de clasificar correctamente los movimientos a partir de los datos del acelerómetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f67ca42-d01f-4d93-b13a-e91644c02b64",
     "showTitle": false,
     "title": ""
    },
    "id": "eZzBRwtU_o79"
   },
   "source": [
    "### **Marco teórico:**\n",
    "\n",
    "El reconocimiento de movimientos a partir de datos de acelerómetro se enmarca dentro del campo del aprendizaje automático y, más específicamente, del aprendizaje profundo. Se emplean técnicas como las redes neuronales convolucionales (CNN), las redes neuronales recurrentes (RNN) y las redes neuronales feed-forward (MLP) para aprender patrones y características relevantes de los datos de acelerómetro y realizar la clasificación de movimientos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0ec6883-7b18-4b88-ac27-cc915747e294",
     "showTitle": false,
     "title": ""
    },
    "id": "XYbVJWTd_x5Y"
   },
   "source": [
    "\n",
    "### **Descripción del problema a solucionar:**\n",
    "\n",
    "El problema consiste en tomar los datos de un acelerómetro, que representan una secuencia de mediciones tridimensionales (x, y, z) a lo largo del tiempo, y clasificarlos en una de las siguientes cinco clases de movimientos: Bicep Curl, Chest Fly, Front Raise, Lateral Raise y Reverse Fly. Estos datos de acelerómetro provienen de dispositivos vestibles utilizados durante la realización de ejercicios de entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb35dff7-f150-4f91-b054-d34e13c75e1b",
     "showTitle": false,
     "title": ""
    },
    "id": "p4mSVC___7kO"
   },
   "source": [
    "### **Planteamiento de la solución:**\n",
    "\n",
    "Para abordar este problema, se plantea el desarrollo y evaluación de tres modelos de aprendizaje profundo: una red neuronal feed-forward (MLP), una red neuronal convolucional 1D (Conv1D) y una red neuronal recurrente (RNN). Estos modelos se entrenan con un conjunto de datos de entrenamiento y se evalúan en un conjunto de datos de prueba. Se realiza un preprocesamiento de los datos, incluyendo la estandarización y la segmentación en patrones de entrada adecuados para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86fca493-eeb2-4dd6-a9e9-2e49d23cc7da",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MUBzdBq0rEG",
    "outputId": "88067e5e-c0fb-4822-ac16-02278936542e"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e28a019-ad49-449f-a159-b91407ae59ab",
     "showTitle": false,
     "title": ""
    },
    "id": "PWhZ0oEbVnV2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ef784c8-fff3-48bd-a9a3-df8aeb6f687c",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 988
    },
    "id": "EzhM9t4qUk1L",
    "outputId": "e6be7db6-7122-4320-db72-c5943993c0a3"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de la carga de un archivo *.json con las mediciones de un acelerómetro\n",
    "RutaFile=\"/content/drive/MyDrive/Colab Notebooks/Datos/Acelerometro/training/Chest_Fly.4r90g5ml.ingestion-848d69cd95-lzk2f.json\"\n",
    "dataframe = pd.read_json(RutaFile)\n",
    "print(dataframe.to_string())\n",
    "Valores = dataframe.iloc[:,:].values\n",
    "print(Valores.shape)\n",
    "print(Valores)\n",
    "print(Valores[7,2][0:-1])\n",
    "\n",
    "DatosOri1=Valores[7,2][0:-1]\n",
    "Datos1=np.array(DatosOri1)\n",
    "print(Datos1.shape)\n",
    "plt.plot(Datos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55f4bb3f-1899-45fb-94f7-4ce3ec7dced8",
     "showTitle": false,
     "title": ""
    },
    "id": "OGTUXIsQSoQf"
   },
   "outputs": [],
   "source": [
    "# Función para cargar datos de un directorio\n",
    "def cargar_datos(directory):\n",
    "    # Obtener la lista de archivos en el directorio y ordenarlos alfabéticamente\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "\n",
    "    # Lista para almacenar los datos de todos los archivos\n",
    "    datos = []\n",
    "\n",
    "    # Leer datos de cada archivo y agregarlos a la lista\n",
    "    for file in files:\n",
    "        # Leer el archivo JSON utilizando Pandas\n",
    "        df = pd.read_json(os.path.join(directory, file))\n",
    "        # Extraer los datos de la columna específica del DataFrame\n",
    "        datos.extend(df.iloc[7, 2][0:-1])\n",
    "\n",
    "    # Convertir la lista de datos a un arreglo numpy\n",
    "    datos = np.array(datos)\n",
    "\n",
    "    return datos\n",
    "\n",
    "# Función para preprocesar los datos para MLP y Conv1D\n",
    "def preprocesar_datos_mlp_conv(datos, scaler):\n",
    "    # Escalar los datos utilizando el objeto scaler proporcionado\n",
    "    datos_esc = scaler.transform(datos)\n",
    "    # Definir el tamaño de la muestra para la entrada del modelo (104 en este caso)\n",
    "    tamano_muestra = 104\n",
    "    # Calcular el número de patrones en los datos escalados\n",
    "    num_patrones = len(datos_esc) // tamano_muestra\n",
    "    # Reorganizar los datos en el formato adecuado para MLP o Conv1D\n",
    "    X = datos_esc[:num_patrones*tamano_muestra].reshape(num_patrones, tamano_muestra, 3)\n",
    "    return X\n",
    "\n",
    "# Función para preprocesar los datos para RNN\n",
    "def preprocesar_datos_rnn(datos, scaler):\n",
    "    # No hay diferencia en el preprocesamiento entre RNN y MLP/Conv1D, se reutiliza la función existente\n",
    "    return preprocesar_datos_mlp_conv(datos, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08bf1510-cca9-4829-85e7-a7cfc2180b9f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRsX1qmj19zq",
    "outputId": "b60194da-c0af-4558-9d15-4d693b9eb21d"
   },
   "outputs": [],
   "source": [
    "# Directorios de datos\n",
    "training_directory = '/content/drive/MyDrive/Colab Notebooks/Datos/Acelerometro/training/'\n",
    "testing_directory = '/content/drive/MyDrive/Colab Notebooks/Datos/Acelerometro/testing/'\n",
    "\n",
    "# Cargar datos de entrenamiento y prueba\n",
    "datos_entrenamiento = cargar_datos(training_directory)\n",
    "datos_prueba = cargar_datos(testing_directory)\n",
    "\n",
    "# Escalar datos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(datos_entrenamiento)\n",
    "# Preprocesar datos para MLP y Conv1D\n",
    "X_entrenamiento_mlp_conv = preprocesar_datos_mlp_conv(datos_entrenamiento, scaler)\n",
    "X_prueba_mlp_conv = preprocesar_datos_mlp_conv(datos_prueba, scaler)\n",
    "# Preprocesar datos para RNN\n",
    "X_entrenamiento_rnn = preprocesar_datos_rnn(datos_entrenamiento, scaler)\n",
    "X_prueba_rnn = preprocesar_datos_rnn(datos_prueba, scaler)\n",
    "\n",
    "# Definir etiquetas de entrenamiento y prueba\n",
    "y_entrenamiento = np.repeat(np.arange(5), len(X_entrenamiento_mlp_conv) // 5)\n",
    "y_prueba = np.repeat(np.arange(5), len(X_prueba_mlp_conv) // 5)\n",
    "\n",
    "# Ajustar el número de etiquetas de prueba para que coincida con el número total de muestras de prueba\n",
    "num_muestras_faltantes = len(X_prueba_mlp_conv) - len(y_prueba)\n",
    "y_prueba = np.concatenate([y_prueba, np.zeros(num_muestras_faltantes)], axis=0)\n",
    "\n",
    "# Convertir etiquetas a formato one-hot\n",
    "Y_entrenamiento = keras.utils.to_categorical(y_entrenamiento)\n",
    "Y_prueba = keras.utils.to_categorical(y_prueba)\n",
    "\n",
    "# Imprimir dimensiones de los datos\n",
    "print(\"Datos Entrenamiento: \", datos_entrenamiento.shape)\n",
    "print(\"Datos Test: \", datos_prueba.shape)\n",
    "print(X_prueba_mlp_conv.shape)\n",
    "print(X_prueba_rnn.shape)\n",
    "print(Y_prueba.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "092424ca-163a-461f-aad4-70d0c34c1afb",
     "showTitle": false,
     "title": ""
    },
    "id": "z0bewtS9dKYH"
   },
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    \"MLP\": keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(tamano_muestra, 3)),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(5, activation=\"softmax\"),  # Corregido a 5 neuronas para 5 clases\n",
    "    ]),\n",
    "    \"Conv1D\": keras.Sequential([\n",
    "        keras.layers.Conv1D(32, 3, activation=\"relu\", input_shape=(tamano_muestra, 3)),\n",
    "        keras.layers.MaxPooling1D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(5, activation=\"softmax\"),  # Corregido a 5 neuronas para 5 clases\n",
    "    ]),\n",
    "    \"RNN\": keras.Sequential([\n",
    "        keras.layers.LSTM(32, input_shape=(tamano_muestra, 3)),\n",
    "        keras.layers.Dense(5, activation=\"softmax\"),  # Corregido a 5 neuronas para 5 clases\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63ccecfb-1133-488b-8881-491b9fb46c08",
     "showTitle": false,
     "title": ""
    },
    "id": "kg_KYneD1y6W"
   },
   "source": [
    "Preprocesamiento de Datos En esta fase cargaremos los datos, los dividiremos en conjuntos de entrenamiento y prueba, y los escalaremos si es necesario.**bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21826def-66e9-4e35-8023-ac02c024ede3",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "teWAhtv6zaAD",
    "outputId": "686d4712-dc70-4478-db9d-182634959704"
   },
   "outputs": [],
   "source": [
    "# Visualización de los datos de entrenamiento (Acelerómetro)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(datos_entrenamiento)\n",
    "plt.title('Datos de entrenamiento (Acelerómetro)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Valor')\n",
    "plt.show()\n",
    "\n",
    "# Visualización de los primeros 100 datos de entrenamiento sin escalar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(datos_entrenamiento[:600])\n",
    "plt.title('Datos de entrenamiento sin escalar')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Valor')\n",
    "plt.show()\n",
    "\n",
    "# Visualización de los primeros 100 datos de entrenamiento escalados\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(scaler.transform(datos_entrenamiento[:600]))\n",
    "plt.title('Datos de entrenamiento escalados')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Valor')\n",
    "plt.show()\n",
    "\n",
    "# Visualización de un patrón de entrenamiento (ejemplo)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_entrenamiento_mlp_conv[0])\n",
    "plt.title('Patrón de entrenamiento (ejemplo)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Valor escalado')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9f51040-2bf3-43f8-ae34-acc131d09a18",
     "showTitle": false,
     "title": ""
    },
    "id": "OhVt5ROA2l0t"
   },
   "source": [
    "Fase 2: Definición y Entrenamiento de Modelos\n",
    "Aquí definiremos los modelos MLP, Conv1D y RNN, los entrenaremos con los datos de entrenamiento y registraremos sus historias de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73eca51e-8b40-46cc-85c3-4e4ff8480b54",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76UmX1Lr2lPO",
    "outputId": "d0300076-f631-470a-a823-c4b14b5b0412"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento y generación de esquemas\n",
    "historias = {}\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando y generando esquema para el modelo {nombre}\")\n",
    "    modelo.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    modelo.summary()  # Mostrar resumen del modelo\n",
    "    historia = modelo.fit(X_entrenamiento_mlp_conv if nombre in [\"MLP\", \"Conv1D\"] else X_entrenamiento_rnn,\n",
    "                           Y_entrenamiento,\n",
    "                           epochs=100,\n",
    "                           batch_size=None if nombre == \"RNN\" else 32,\n",
    "                           verbose=0)\n",
    "    historias[nombre] = historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50353991-ee24-45a0-891b-c61bd7b6a3c3",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sHAW3kyfP9CU",
    "outputId": "a94823ef-3c81-4471-e490-d56ac2af8051"
   },
   "outputs": [],
   "source": [
    "# Gráfica de la evolución de la pérdida durante el entrenamiento\n",
    "plt.figure(figsize=(10, 6))\n",
    "for nombre, historia in historias.items():\n",
    "    plt.plot(historia.history['loss'], label=nombre)\n",
    "plt.title('Evolución de la pérdida durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráficas de la evolución de la pérdida durante el entrenamiento para cada modelo\n",
    "for nombre, historia in historias.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(historia.history['loss'])\n",
    "    plt.title(f'Evolución de la pérdida durante el entrenamiento - {nombre}')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1d526c9-e970-4384-8178-333b8dc7169a",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KMhDkO9QBfXC",
    "outputId": "4d224bbc-9526-49a4-ee68-06eb79bd5ebd"
   },
   "outputs": [],
   "source": [
    "# Evaluación de modelos y visualización de la matriz de confusión\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Modelo: {nombre}\")\n",
    "    resultados = modelo.evaluate(X_prueba_mlp_conv if nombre in [\"MLP\", \"Conv1D\"] else X_prueba_rnn,\n",
    "                                  Y_prueba,\n",
    "                                  verbose=0)\n",
    "    print(\"Pérdida:\", resultados[0])\n",
    "    print(\"Precisión:\", resultados[1])\n",
    "\n",
    "    # Predicciones y matriz de confusión\n",
    "    predicciones = modelo.predict(X_prueba_mlp_conv if nombre in [\"MLP\", \"Conv1D\"] else X_prueba_rnn)\n",
    "    y_pred_class = np.argmax(predicciones, axis=1)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    cm = confusion_matrix(y_prueba, y_pred_class)\n",
    "    print(cm)\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_prueba, y_pred_class))\n",
    "\n",
    "    # Gráfica de la matriz de confusión\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f'Matriz de Confusión - {nombre}')\n",
    "    plt.xlabel('Predicciones')\n",
    "    plt.ylabel('Valores verdaderos')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a977c5d-1ddc-4cd1-8fd7-12a76529b64f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njGl0lhOFIiD",
    "outputId": "b49783d5-d9c5-4c8a-bc20-00ecd1e1ef33"
   },
   "outputs": [],
   "source": [
    "# Evaluación de modelos y selección del mejor modelo\n",
    "mejor_modelo = None\n",
    "mejor_precision = 0\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    # Entrenar el modelo y guardar la historia\n",
    "    historia = modelo.fit(X_entrenamiento_mlp_conv if nombre in [\"MLP\", \"Conv1D\"] else X_entrenamiento_rnn,\n",
    "                           Y_entrenamiento,\n",
    "                           epochs=100,\n",
    "                           batch_size=None if nombre == \"RNN\" else 32,\n",
    "                           verbose=0)\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    resultados = modelo.evaluate(X_prueba_mlp_conv if nombre in [\"MLP\", \"Conv1D\"] else X_prueba_rnn,\n",
    "                                  Y_prueba,\n",
    "                                  verbose=0)\n",
    "    perdida = resultados[0]\n",
    "    precision = resultados[1]\n",
    "\n",
    "    # Imprimir los resultados\n",
    "    print(f\"Modelo: {nombre}\")\n",
    "    print(\"Pérdida:\", perdida)\n",
    "    print(\"Precisión:\", precision)\n",
    "\n",
    "    # Comparar con el mejor modelo actual\n",
    "    if precision > mejor_precision:\n",
    "        mejor_modelo = nombre\n",
    "        mejor_precision = precision\n",
    "\n",
    "# Imprimir el mejor modelo y su precisión\n",
    "print(f\"El mejor modelo es {mejor_modelo} con una precisión de {mejor_precision}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc264c61-c177-45bb-bb08-1bc6a05bd95f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nreWIPQ1E_z-",
    "outputId": "29fcea87-9e13-4e00-db15-5b9005ebe33d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Código para crear y compilar el modelo\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(32, 3, activation='relu', input_shape=(104, 3)),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')  # El número de clases es 5 según el contexto\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "# ...\n",
    "\n",
    "# Guardar el modelo en formato h5\n",
    "modelo.save('modelo.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb108c3d-d512-4dbc-bacf-b4874bc710b8",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6R36xqwDFlcA",
    "outputId": "a38ce509-3359-4260-ded2-7a3d6f2c81db"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo\n",
    "modelo = tf.keras.models.load_model('modelo.h5')\n",
    "\n",
    "# Función para cargar y preprocesar los datos de un archivo JSON\n",
    "def cargar_datos_json(archivo_json):\n",
    "    with open(archivo_json, 'r') as f:\n",
    "        datos_json = json.load(f)\n",
    "\n",
    "    # Extraer los valores del \"payload\"\n",
    "    valores = datos_json['payload']['values']\n",
    "\n",
    "    # Convertir los valores a un arreglo numpy\n",
    "    datos_acelerometro = np.array(valores)\n",
    "\n",
    "    return datos_acelerometro\n",
    "\n",
    "\n",
    "# Función para inferir la clase a partir de las predicciones\n",
    "def inferir_clase(prediccion):\n",
    "    clases = ['Bicep_Curl', 'Chest_Fly', 'Front_Raise', 'Lateral_Raise', 'reverse_Fly']\n",
    "    indice_clase = np.argmax(prediccion)\n",
    "    return clases[indice_clase]\n",
    "\n",
    "# Ruta al archivo JSON que contiene los datos del acelerómetro\n",
    "archivo_json = '/content/Bicep_Curl.4r90jnsk.ingestion-848d69cd95-ttl72.json'\n",
    "\n",
    "# Cargar y preprocesar los datos\n",
    "datos_acelerometro = cargar_datos_json(archivo_json)\n",
    "\n",
    "# Asegurarnos de que los datos tienen al menos 104 muestras\n",
    "if datos_acelerometro.shape[0] < 104:\n",
    "    print(\"El archivo JSON no tiene suficientes muestras para realizar una predicción.\")\n",
    "else:\n",
    "    # Tomar solo las primeras 104 muestras (o ajustar según sea necesario)\n",
    "    datos_acelerometro = datos_acelerometro[:104]\n",
    "\n",
    "    # Realizar la predicción\n",
    "    prediccion = modelo.predict(datos_acelerometro.reshape(1, 104, 3))  # Reshape para que coincida con la forma esperada por el modelo\n",
    "\n",
    "    # Obtener la clase predicha\n",
    "    clase_predicha = inferir_clase(prediccion)\n",
    "    print(\"Clase predicha:\", clase_predicha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c31d5b7d-2215-4dcb-ad23-59f8ff21daf5",
     "showTitle": false,
     "title": ""
    },
    "id": "z8vua_-gAdPh"
   },
   "source": [
    "### **Resultados:**\n",
    "\n",
    "En el código, se entrenan y evalúan tres modelos de aprendizaje profundo: una red neuronal feed-forward (MLP), una red neuronal convolucional 1D (Conv1D) y una red neuronal recurrente (RNN). Los modelos se entrenan con un conjunto de datos de entrenamiento y se evalúan en un conjunto de datos de prueba.\n",
    "\n",
    "Se muestran las métricas de rendimiento, como la pérdida y la precisión, para cada modelo en el conjunto de prueba:\n",
    "\n",
    "MLP:\n",
    "Pérdida: 2.369173288345337\n",
    "Precisión: 0.7627118825912476\n",
    "\n",
    "Conv1D:\n",
    "Pérdida: 2.7176055908203125\n",
    "Precisión: 0.7627118825912476\n",
    "\n",
    "RNN:\n",
    "Pérdida: 1.602267861366272\n",
    "Precisión: 0.7288135886192322\n",
    "\n",
    "Además, se calculan las matrices de confusión y los reportes de clasificación para cada modelo, lo que permite evaluar el rendimiento en términos de precisión, recall y F1-score para cada clase.\n",
    "\n",
    "Finalmente, se selecciona el mejor modelo basado en la precisión en el conjunto de prueba, siendo el modelo MLP el que obtuvo la mayor precisión de 0.7627118825912476."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe4f12d-d390-4700-88c8-0d61fd2d3615",
     "showTitle": false,
     "title": ""
    },
    "id": "VJNjR2L0Akl2"
   },
   "source": [
    "### **Conclusiones:**\n",
    "\n",
    "Los resultados obtenidos muestran que los tres modelos evaluados (MLP, Conv1D y RNN) lograron un rendimiento similar en la clasificación de movimientos a partir de los datos del acelerómetro. Sin embargo, el modelo MLP tuvo un ligero mejor desempeño en términos de precisión en el conjunto de prueba.\n",
    "\n",
    "Es importante mencionar que los modelos podrían mejorarse aún más mediante la optimización de hiperparámetros, como el número de épocas de entrenamiento, el tamaño de lote y las tasas de aprendizaje. Además, se podrían explorar arquitecturas más complejas o técnicas adicionales, como la regularización o el aumento de datos, para mejorar el rendimiento y la capacidad de generalización de los modelos.\n",
    "\n",
    "Una limitación importante del enfoque actual es que los modelos se entrenan y evalúan utilizando un conjunto de datos único. Para obtener resultados más robustos y confiables, sería recomendable evaluar los modelos en múltiples conjuntos de datos, posiblemente recopilados en diferentes entornos y condiciones.\n",
    "\n",
    "En general, este trabajo demuestra el potencial del aprendizaje profundo para abordar el problema de la clasificación de movimientos a partir de datos de acelerómetro, pero también resalta la necesidad de continuar explorando y mejorando los enfoques utilizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64c595a0-e456-436b-ba8d-9ecf6b95b67d",
     "showTitle": false,
     "title": ""
    },
    "id": "5arfmWIFAnQB"
   },
   "source": [
    "### **Referencias:**\n",
    "\n",
    "Brownlee, J. (2020). Deep Learning for Time Series Forecasting. Machine Learning Mastery.\n",
    "\n",
    "Zhang, M., Sawchuk, A. A. (2012). Human Daily Activity Recognition With Sparse Representation Using Wearable Sensors. IEEE Journal of Biomedical and Health Informatics, 16(3), 553-560.\n",
    "\n",
    "Ronao, C. A., Cho, S. B. (2016). Human activity recognition with smartphone sensors using deep learning neural networks. Expert Systems with Applications, 59, 235-244.\n",
    "\n",
    "Tensorflow: https://www.tensorflow.org/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Taller1_Acelerometro",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
