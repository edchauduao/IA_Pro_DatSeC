{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52c32b80-74c8-4287-84cc-3054937a28d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Descripción del Problema\n",
    "\n",
    "El objetivo de este ejercicio es crear un prototipo de aplicación utilizando la API del modelo GPT-3 liberado por OpenAI. La aplicación permitirá a los usuarios interactuar con el modelo GPT-3 para generar texto a partir de una entrada dada.\n",
    "\n",
    "### Herramientas y Servicios a Utilizar\n",
    "\n",
    "- **OpenAI GPT-3 API:** Utilizaremos la API de OpenAI GPT-3 para generar texto.\n",
    "  \n",
    "- **Azure Cognitive Search:** Utilizaremos Azure Cognitive Search para indexar y buscar información dentro de documentos PDF.\n",
    "  \n",
    "- **Azure Blob Storage:** Almacenaremos documentos PDF relacionados con la Especialización en IA de la UAO en Azure Blob Storage para su posterior búsqueda.\n",
    "\n",
    "### Pasos a Seguir\n",
    "\n",
    "1. **Cargar los Documentos en Azure Blob Storage:** Subiremos documentos relacionados con la Especialización en IA de la UAO a Azure Blob Storage para que estén disponibles para el servicio de Cognitive Search.\n",
    "   \n",
    "2. **Configurar Azure Cognitive Search:** Configuraremos un índice en Azure Cognitive Search para indexar los documentos PDF almacenados en Azure Blob Storage.\n",
    "   \n",
    "3. **Interactuar con la API de GPT-3:** Utilizaremos la API de OpenAI GPT-3 para generar texto a partir de la entrada del usuario. Esto incluirá la generación de respuestas a preguntas, completar frases, y más.\n",
    "   \n",
    "4. **Integrar la Búsqueda en el Prototipo de Aplicación:** Implementaremos una función en el prototipo de aplicación que permita a los usuarios buscar información dentro de los documentos PDF utilizando Azure Cognitive Search.\n",
    "   \n",
    "5. **Evaluar el Modelo GPT-3 Turbo y DALLE-3:** Probaremos tanto el modelo GPT-3 Turbo como el modelo DALLE-3 para evaluar su desempeño y determinar cuál es más adecuado para nuestras necesidades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6e395ea-298a-4be7-9783-c8bde5431efa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "# Función para cargar las variables de entorno desde el archivo .env\n",
    "def load_environment_variables():\n",
    "    dotenv.load_dotenv()\n",
    "    return (\n",
    "        os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  # Endpoint de la API de OpenAI\n",
    "        os.getenv(\"AZURE_OPENAI_API_KEY\"),   # Clave de la API de OpenAI\n",
    "        os.getenv(\"SEARCH_ENDPOINT\"),        # Endpoint de Azure Cognitive Search\n",
    "        os.getenv(\"SEARCH_KEY\"),             # Clave de Azure Cognitive Search\n",
    "        os.getenv(\"SEARCH_INDEX_NAME\")       # Nombre del índice en Azure Cognitive Search\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fd0a8da-f4b5-4fe0-a6af-37e6568a957c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_openai_completion(content):\n",
    "    # Cargar las variables de entorno\n",
    "    endpoint, api_key, search_endpoint, search_key, search_index = load_environment_variables()\n",
    "    \n",
    "    # Nombre del despliegue de OpenAI\n",
    "    deployment = \"Taller_gpt\"\n",
    "\n",
    "    # Crear un cliente para interactuar con la API de OpenAI\n",
    "    client = openai.AzureOpenAI(\n",
    "        base_url=f\"{endpoint}/openai/deployments/{deployment}/extensions\",  # URL base del despliegue de OpenAI\n",
    "        api_key=api_key,  # Clave de la API de OpenAI\n",
    "        api_version=\"2023-09-01-preview\"  # Versión de la API\n",
    "    )\n",
    "\n",
    "    # Crear una solicitud de completado utilizando el modelo GPT-3\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],  # Mensaje del usuario\n",
    "        model=deployment,  # Nombre del modelo GPT-3 a utilizar\n",
    "        extra_body={\n",
    "            \"dataSources\": [\n",
    "                {\n",
    "                    \"type\": \"AzureCognitiveSearch\",  # Tipo de fuente de datos (Azure Cognitive Search)\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": search_endpoint,    # Endpoint de Azure Cognitive Search\n",
    "                        \"key\": search_key,              # Clave de Azure Cognitive Search\n",
    "                        \"indexName\": search_index,      # Nombre del índice en Azure Cognitive Search\n",
    "                        \"roleInformation\": \"Eres un asistente de IA que ayuda con información de la Especialización en IA de la UAO\",  # Información sobre el rol del asistente\n",
    "                        \"semanticConfiguration\": \"default\",  # Configuración semántica\n",
    "                        \"queryType\": \"simple\",          # Tipo de consulta\n",
    "                        \"fieldsMapping\": {},            # Mapeo de campos\n",
    "                        \"inScope\": True,                # Si está en el ámbito de búsqueda\n",
    "                        \"strictness\": 3,                # Rigurosidad de la búsqueda\n",
    "                        \"topNDocuments\": 5,             # Número máximo de documentos a devolver\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Retornar la respuesta generada por GPT-3\n",
    "    return f\"{completion.choices[0].message.content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94375914-153d-4b1b-987e-ac87fda9bbcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo de uso:\n",
    "content = \"Quien es el coordinador de la especialización?\"\n",
    "response = run_openai_completion(content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a566932-2269-4eb3-967b-3d50c7ac67a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Bienvenido al Chat con el Asistente IA\\n\")\n",
    "    print(\"Puedes escribir tus mensajes a continuación. Escribe 'salir' para terminar.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Tú: \")\n",
    "        print(\"Usuario:\", user_input)\n",
    "\n",
    "        if user_input.lower() == \"salir\":\n",
    "            print(\"Hasta luego!\")\n",
    "            break\n",
    "\n",
    "        response = run_openai_completion(user_input)\n",
    "        print(\"Asistente IA:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "706dcb12-7033-4e7e-9ebc-627e6fd56c80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Crear un cliente para interactuar con la API de OpenAI\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",  # Versión de la API\n",
    "    azure_endpoint=\"https://base-ia-openai.openai.azure.com/\",  # Endpoint de la API de Azure OpenAI\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],  # Clave de la API de OpenAI\n",
    ")\n",
    "\n",
    "# Generar una imagen utilizando DALL-E 3\n",
    "result = client.images.generate(\n",
    "    model=\"Dalle3\",  # Nombre del modelo DALL-E 3\n",
    "    prompt=\"Creame un avatar con una mezcla de ave rapaz y un ser humano\",  # Prompt para la generación de la imagen\n",
    "    n=1  # Número de imágenes a generar\n",
    ")\n",
    "\n",
    "# Obtener la URL de la imagen generada\n",
    "image_url = json.loads(result.model_dump_json())['data'][0]['url']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e132203-9673-419d-b212-14e709a904ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Descargar la imagen utilizando su URL\n",
    "response = requests.get(image_url)\n",
    "\n",
    "# Abrir la imagen descargada utilizando PIL (Python Imaging Library)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Mostrar la imagen en una ventana emergente\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89f65074-c8a1-4c55-82f9-a5d7b80c0a04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Nombre del despliegue de OpenAI para embeddings\n",
    "deployment = \"Embed\"\n",
    "\n",
    "# Crear embeddings utilizando el modelo especificado\n",
    "embeddings = client.embeddings.create(\n",
    "    model=deployment,  # Nombre del modelo\n",
    "    input=\"The food was delicious and the waiter...\"  # Texto de entrada para generar embeddings\n",
    ")\n",
    "\n",
    "# Imprimir los embeddings generados\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "326a9729-9991-4280-a948-be2dbd2ce064",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Conclusiones Técnicas:\n",
    "\n",
    "1. **Integración de OpenAI GPT-3 y Azure Cognitive Search:** La combinación de la API de OpenAI GPT-3 y Azure Cognitive Search permite una integración efectiva entre generación de texto y búsqueda de información en documentos PDF. Esto proporciona a los usuarios una experiencia más completa y enriquecedora al interactuar con la aplicación.\n",
    "\n",
    "2. **Configuración de Azure Cognitive Search:** La configuración de Azure Cognitive Search para indexar y buscar información dentro de documentos PDF facilita la recuperación de datos relevantes para el usuario. La configuración adecuada de los parámetros, como el tipo de consulta y el número máximo de documentos a devolver, es crucial para obtener resultados precisos.\n",
    "\n",
    "3. **Uso de modelos de lenguaje avanzados:** La utilización de modelos de lenguaje avanzados como GPT-3 y DALLE-3 permite generar texto de manera autónoma y responder a las consultas de los usuarios de manera más natural y efectiva.\n",
    "\n",
    "4. **Pruebas y evaluación de modelos:** Es importante realizar pruebas y evaluaciones exhaustivas de los modelos GPT-3 y DALLE-3 para determinar cuál es más adecuado para las necesidades específicas de la aplicación. Esto implica evaluar la calidad de las respuestas generadas, así como el rendimiento y la eficiencia de cada modelo.\n",
    "\n",
    "## Conclusiones Generales:\n",
    "\n",
    "1. **Capacidad de generación de texto:** La aplicación permite a los usuarios generar texto de manera libre y obtener respuestas pertinentes a sus consultas. Esto facilita la interacción con la información y puede ser útil en una variedad de contextos, desde la investigación académica hasta la resolución de problemas prácticos.\n",
    "\n",
    "2. **Facilidad de acceso a la información:** La integración con Azure Cognitive Search permite a los usuarios buscar información específica dentro de documentos PDF relacionados con la Especialización en IA de la UAO de manera rápida y eficiente. Esto mejora la accesibilidad a la información y facilita la toma de decisiones informadas.\n",
    "\n",
    "3. **Aplicabilidad en diversos escenarios:** La aplicación puede ser útil en una variedad de escenarios, incluyendo la educación, la investigación y la industria. La capacidad de generar texto y buscar información de manera inteligente puede mejorar la productividad y la eficiencia en diferentes contextos.\n",
    "\n",
    "4. **Potencial de mejora continua:** Aunque el prototipo de la aplicación funciona correctamente, siempre hay margen para mejoras adicionales. Esto puede incluir la optimización de los modelos de lenguaje, la mejora de la precisión de la búsqueda y la expansión de las funcionalidades ofrecidas a los usuarios.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gpt3_tallerfinal",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
