{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52c32b80-74c8-4287-84cc-3054937a28d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Descripción del Problema\n",
    "\n",
    "El objetivo de este ejercicio es crear un prototipo de aplicación utilizando la API del modelo GPT-3 liberado por OpenAI. La aplicación permitirá a los usuarios interactuar con el modelo GPT-3 para generar texto a partir de una entrada dada.\n",
    "\n",
    "### Herramientas y Servicios a Utilizar\n",
    "\n",
    "- **OpenAI GPT-3 API:** Utilizaremos la API de OpenAI GPT-3 para generar texto.\n",
    "  \n",
    "- **Azure Cognitive Search:** Utilizaremos Azure Cognitive Search para indexar y buscar información dentro de documentos PDF.\n",
    "  \n",
    "- **Azure Blob Storage:** Almacenaremos documentos PDF relacionados con la Especialización en IA de la UAO en Azure Blob Storage para su posterior búsqueda.\n",
    "\n",
    "### Pasos a Seguir\n",
    "\n",
    "1. **Cargar los Documentos en Azure Blob Storage:** Subiremos documentos relacionados con la Especialización en IA de la UAO a Azure Blob Storage para que estén disponibles para el servicio de Cognitive Search.\n",
    "   \n",
    "2. **Configurar Azure Cognitive Search:** Configuraremos un índice en Azure Cognitive Search para indexar los documentos PDF almacenados en Azure Blob Storage.\n",
    "   \n",
    "3. **Interactuar con la API de GPT-3:** Utilizaremos la API de OpenAI GPT-3 para generar texto a partir de la entrada del usuario. Esto incluirá la generación de respuestas a preguntas, completar frases, y más.\n",
    "   \n",
    "4. **Integrar la Búsqueda en el Prototipo de Aplicación:** Implementaremos una función en el prototipo de aplicación que permita a los usuarios buscar información dentro de los documentos PDF utilizando Azure Cognitive Search.\n",
    "   \n",
    "5. **Evaluar el Modelo GPT-3 Turbo y DALLE-3:** Probaremos tanto el modelo GPT-3 Turbo como el modelo DALLE-3 para evaluar su desempeño y determinar cuál es más adecuado para nuestras necesidades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6e395ea-298a-4be7-9783-c8bde5431efa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "# Función para cargar las variables de entorno desde el archivo .env\n",
    "def load_environment_variables():\n",
    "    dotenv.load_dotenv()\n",
    "    return (\n",
    "        os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  # Endpoint de la API de OpenAI\n",
    "        os.getenv(\"AZURE_OPENAI_API_KEY\"),   # Clave de la API de OpenAI\n",
    "        os.getenv(\"SEARCH_ENDPOINT\"),        # Endpoint de Azure Cognitive Search\n",
    "        os.getenv(\"SEARCH_KEY\"),             # Clave de Azure Cognitive Search\n",
    "        os.getenv(\"SEARCH_INDEX_NAME\")       # Nombre del índice en Azure Cognitive Search\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fd0a8da-f4b5-4fe0-a6af-37e6568a957c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_openai_completion(content):\n",
    "    # Cargar las variables de entorno\n",
    "    endpoint, api_key, search_endpoint, search_key, search_index = load_environment_variables()\n",
    "    \n",
    "    # Nombre del despliegue de OpenAI\n",
    "    deployment = \"Taller_gpt\"\n",
    "\n",
    "    # Crear un cliente para interactuar con la API de OpenAI\n",
    "    client = openai.AzureOpenAI(\n",
    "        base_url=f\"{endpoint}/openai/deployments/{deployment}/extensions\",  # URL base del despliegue de OpenAI\n",
    "        api_key=api_key,  # Clave de la API de OpenAI\n",
    "        api_version=\"2023-09-01-preview\"  # Versión de la API\n",
    "    )\n",
    "\n",
    "    # Crear una solicitud de completado utilizando el modelo GPT-3\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],  # Mensaje del usuario\n",
    "        model=deployment,  # Nombre del modelo GPT-3 a utilizar\n",
    "        extra_body={\n",
    "            \"dataSources\": [\n",
    "                {\n",
    "                    \"type\": \"AzureCognitiveSearch\",  # Tipo de fuente de datos (Azure Cognitive Search)\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": search_endpoint,    # Endpoint de Azure Cognitive Search\n",
    "                        \"key\": search_key,              # Clave de Azure Cognitive Search\n",
    "                        \"indexName\": search_index,      # Nombre del índice en Azure Cognitive Search\n",
    "                        \"roleInformation\": \"Eres un asistente de IA que ayuda con información de la Especialización en IA de la UAO\",  # Información sobre el rol del asistente\n",
    "                        \"semanticConfiguration\": \"default\",  # Configuración semántica\n",
    "                        \"queryType\": \"simple\",          # Tipo de consulta\n",
    "                        \"fieldsMapping\": {},            # Mapeo de campos\n",
    "                        \"inScope\": True,                # Si está en el ámbito de búsqueda\n",
    "                        \"strictness\": 3,                # Rigurosidad de la búsqueda\n",
    "                        \"topNDocuments\": 5,             # Número máximo de documentos a devolver\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Retornar la respuesta generada por GPT-3\n",
    "    return f\"{completion.choices[0].message.content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94375914-153d-4b1b-987e-ac87fda9bbcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo de uso:\n",
    "content = \"Quien es el coordinador de la especialización?\"\n",
    "response = run_openai_completion(content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a566932-2269-4eb3-967b-3d50c7ac67a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Bienvenido al Chat con el Asistente IA\\n\")\n",
    "    print(\"Puedes escribir tus mensajes a continuación. Escribe 'salir' para terminar.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Tú: \")\n",
    "        print(\"Usuario:\", user_input)\n",
    "\n",
    "        if user_input.lower() == \"salir\":\n",
    "            print(\"Hasta luego!\")\n",
    "            break\n",
    "\n",
    "        response = run_openai_completion(user_input)\n",
    "        print(\"Asistente IA:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "706dcb12-7033-4e7e-9ebc-627e6fd56c80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Crear un cliente para interactuar con la API de OpenAI\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",  # Versión de la API\n",
    "    azure_endpoint=\"https://base-ia-openai.openai.azure.com/\",  # Endpoint de la API de Azure OpenAI\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],  # Clave de la API de OpenAI\n",
    ")\n",
    "\n",
    "# Generar una imagen utilizando DALL-E 3\n",
    "result = client.images.generate(\n",
    "    model=\"Dalle3\",  # Nombre del modelo DALL-E 3\n",
    "    prompt=\"Creame un avatar con una mezcla de ave rapaz y un ser humano\",  # Prompt para la generación de la imagen\n",
    "    n=1  # Número de imágenes a generar\n",
    ")\n",
    "\n",
    "# Obtener la URL de la imagen generada\n",
    "image_url = json.loads(result.model_dump_json())['data'][0]['url']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e132203-9673-419d-b212-14e709a904ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Descargar la imagen utilizando su URL\n",
    "response = requests.get(image_url)\n",
    "\n",
    "# Abrir la imagen descargada utilizando PIL (Python Imaging Library)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Mostrar la imagen en una ventana emergente\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89f65074-c8a1-4c55-82f9-a5d7b80c0a04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Nombre del despliegue de OpenAI para embeddings\n",
    "deployment = \"Embed\"\n",
    "\n",
    "# Crear embeddings utilizando el modelo especificado\n",
    "embeddings = client.embeddings.create(\n",
    "    model=deployment,  # Nombre del modelo\n",
    "    input=\"The food was delicious and the waiter...\"  # Texto de entrada para generar embeddings\n",
    ")\n",
    "\n",
    "# Imprimir los embeddings generados\n",
    "print(embeddings)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gpt3_tallerfinal",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
